{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40fe1e66-56c3-4105-b954-dd2b93d7999b",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "https://surfdrive.surf.nl/files/index.php/s/iiACJcCJyQK8WD5\n",
    "\n",
    "and put the data somewhere where python can see it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54206e98-aa11-4cf7-8c57-3049e55f2a95",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec68e29-b345-4579-890f-f62919d81e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if your are working locally do something like\n",
    "!pip install numpy pandas matplotlib seaborn sklearn pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b936c1e-735a-4ac6-a860-5162913f87e7",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e977433-33c2-4317-bae0-97dbc1ad541c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210cf08-8a30-4325-b85b-67fa95102cf0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load and Investigate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d469c92-ba5a-42be-9cd6-fd12ce2a2a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../../hippocampus_data.pkl', 'rb') as f:\n",
    "    all_betas = pkl.load(f)\n",
    "\n",
    "all_betas['DG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838b740-2840-4bb0-a65b-dea920f00e0e",
   "metadata": {},
   "source": [
    "### Visualize Features of Some Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3600343-6c10-435b-ad48-715a0b3debf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(all_betas['DG'][['BarackObama1_pa_cong', 'GeorgeBush1_ga_cong']].T)\n",
    "plt.title('Some Congruent Trials')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3173edf-9f22-477e-ad84-432f389ea819",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Visualize some incongruent trials..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b70064-ed84-41b6-b2a9-18c8782d6e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# <Your Code Goes Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8662bc9-69cf-4cff-ae6e-f44dbdb08bbd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Decoding $Congruent$ vs. $Incongruent$ Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2f82f-eeec-4c46-8a76-acd584d4bf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick region\n",
    "region = 'CA2'\n",
    "\n",
    "# set some hyper-parameters\n",
    "train_test_ratio = .75\n",
    "nr_of_selected_features = 200\n",
    "regularization_penalty = 1.\n",
    "max_iter = 200\n",
    "\n",
    "# pick a balanced number of samples from both conditions\n",
    "dataset = pd.concat([all_betas[region].filter(regex='_cong').iloc[:, np.random.choice(range(144), 24, replace=False)], all_betas[region].filter(regex='_incong')], axis=1)\n",
    "betas = dataset.values.T\n",
    "conds = dataset.columns.map(lambda x: 1 if '_cong' in x else 0) # encode classes\n",
    "betas, conds = shuffle(betas, conds)\n",
    "\n",
    "# split into train/test 75%/25%\n",
    "n_trials = dataset.shape[1]\n",
    "train_indices = np.random.choice(range(n_trials), int(train_test_ratio*n_trials), replace=False)\n",
    "betas_train = betas[train_indices,:]\n",
    "conds_train = conds[train_indices]\n",
    "test_indices = [trial for trial in np.arange(n_trials) if trial not in train_indices]\n",
    "betas_test = betas[test_indices,:]\n",
    "conds_test = conds[test_indices]\n",
    "\n",
    "# 1. Data Preprocessing \n",
    "# <was already performed.>\n",
    "\n",
    "# 2. Normalize Data\n",
    "betas_train = (betas_train-betas_train.mean())/betas_train.std()\n",
    "betas_test = (betas_test-betas_train.mean())/betas_train.std() # we need to normalize using the train set to prevent information leakage\n",
    "\n",
    "# 3. Select Features\n",
    "feature_selection = SelectKBest(f_classif, k=nr_of_selected_features)\n",
    "feature_selection.fit_transform(betas_train, conds_train).shape\n",
    "selected_features = feature_selection.get_support(indices=True)\n",
    "betas_train_selected = betas_train[:, selected_features]\n",
    "betas_test_selected = betas_test[:, selected_features] # note that we are using the statistics from the train set again to prevent information leakage\n",
    "\n",
    "# 4. Select Model\n",
    "decoder = LogisticRegression(C=regularization_penalty, max_iter=max_iter)\n",
    "\n",
    "# 5. Train Model\n",
    "decoder.fit(betas_train_selected, conds_train)\n",
    "\n",
    "y_predicted = decoder.predict(betas_test_selected)\n",
    "\n",
    "acc = (y_predicted==conds_test).sum()/conds_test.size\n",
    "\n",
    "print(f'Accuracy of predicted (i.e. decoded) conditions: {acc:0.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a7d83-07d1-468b-8e15-144a2564db9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Copy and paste below the code in the above cell to wrap it a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4e333-c9be-4b9f-823f-cdd95c94bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pick region\n",
    "region = 'CA2'\n",
    "\n",
    "# set some hyper-parameters\n",
    "train_test_ratio = .75\n",
    "nr_of_selected_features = 200\n",
    "regularization_penalty = 1.\n",
    "max_iter = 200\n",
    "\n",
    "acc_list = []\n",
    "for _ in range(100):\n",
    "\n",
    "    # <your code goes here>\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "\n",
    "    # here we print the mean and std of our obtained accuracies\n",
    "print(f'Mean accuracy of predicted conditions: {np.mean(acc_list):0.2f}+-{np.std(acc_list):0.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5b1a7-6598-44c3-88c8-49c360feb46e",
   "metadata": {},
   "source": [
    "Now we can estimate the confidence in our decoder.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "**Copy the code again below. Now test the different regions and adjust the following parameters to see if you can get an improved decoding accuracy:**\n",
    "- region (DG, SUB, CA1, CA2, CA3)\n",
    "- train_test_ratio (.5, 2/3, 3/4, 5/6)\n",
    "- nr_of_selected_features (10, 50, 100, 200, 300)\n",
    "- regularization_penalty = (0.001, 0.01, 0.1, 1., 10.)\n",
    "- max_iter (100, 200, 500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877d2e1-a4ae-4382-acbe-31e0cc22dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Your Code Goes Here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151aebe3-c771-4cb5-9c4a-e3a0c4e6e0c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### We have seen above that there seems to be some information related to the experiment in the representations within hippocampus. **Let's now make this splitting of the data more systematic using a machine learning pipeline and cross-validation.** We will try to decode PA vs. GA instead of congruent vs. incongruent.\n",
    "\n",
    "\n",
    "# Decoding $PA$ vs. $GA$ Trials using a (LOO) Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0c7c7-2f09-4390-91d3-3211b2a7d896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "accs = {\n",
    "    'cong': [], 'cong+incong(stim)': [], 'cong+incong(pred)': [], 'cong+omis': []\n",
    "}\n",
    "\n",
    "for region, df_betas in all_betas.items():\n",
    "\n",
    "    # prepare congruent trials\n",
    "    df_cong = df_betas.filter(regex='_cong')\n",
    "    X = df_cong.values.T\n",
    "    y = df_cong.columns.map(lambda x: 0. if '_pa_' in x else 1.).values\n",
    "\n",
    "    # add incongruent trials\n",
    "    df_incong = df_betas.filter(regex='_incong')\n",
    "    X_incong = np.vstack([X, df_incong.values.T])\n",
    "    y_heard = np.concatenate([y, df_incong.columns.map(lambda x: 0. if '_pa_' in x else 1.).values])\n",
    "    y_pred = np.concatenate([y, df_incong.columns.map(lambda x: 1. if '_pa_' in x else 0.).values])\n",
    "\n",
    "    # add omitted trials\n",
    "    df_omis = df_betas.filter(regex='_omis')\n",
    "    X_omis = np.vstack([X, df_omis.values.T])\n",
    "    y_omis = np.concatenate([y, df_omis.columns.map(lambda x: 0. if '_pa_' in x else 1.).values])\n",
    "    \n",
    "\n",
    "    accs['cong'].append(cross_val_score(pipeline, X, y, cv=LeaveOneOut()))\n",
    "    accs['cong+incong(stim)'].append(cross_val_score(pipeline, X_incong, y_heard, cv=LeaveOneOut()))\n",
    "    accs['cong+incong(pred)'].append(cross_val_score(pipeline, X_incong, y_pred, cv=LeaveOneOut()))\n",
    "    accs['cong+omis'].append(cross_val_score(pipeline, X_omis, y_omis, cv=LeaveOneOut()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419942b-199a-4346-bc05-ee65e59268b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(16,4))\n",
    "\n",
    "for idx, key in enumerate(accs.keys()):\n",
    "    sns.barplot(accs[key], ax=ax[idx], capsize=.1)\n",
    "    ax[idx].axhline(.5, c='k', linestyle='--')\n",
    "    ax[idx].set_title(key)\n",
    "    ax[idx].set_xticks(range(5), all_betas.keys())\n",
    "    if idx==0: ax[idx].set_ylabel('acc')\n",
    "\n",
    "plt.suptitle('PA vs. GA Classification Results', fontweight='bold', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546f92e-f986-4327-9c1c-6305724ca749",
   "metadata": {},
   "source": [
    "# Let's see if feature selection will change / improve our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a49c7d-a662-4c12-a019-49e90c27546e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_percentage = .1\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectKBest(f_classif)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "accs = {\n",
    "    'cong': [], 'cong+incong(stim)': [], 'cong+incong(pred)': [], 'cong+omis': []\n",
    "}\n",
    "\n",
    "for region, df_betas in all_betas.items():\n",
    "\n",
    "    # prepare congruent trials\n",
    "    df_cong = df_betas.filter(regex='_cong')\n",
    "    X = df_cong.values.T\n",
    "    y = df_cong.columns.map(lambda x: 0. if '_pa_' in x else 1.).values\n",
    "\n",
    "    # add incongruent trials\n",
    "    df_incong = df_betas.filter(regex='_incong')\n",
    "    X_incong = np.vstack([X, df_incong.values.T])\n",
    "    y_heard = np.concatenate([y, df_incong.columns.map(lambda x: 0. if '_pa_' in x else 1.).values])\n",
    "    y_pred = np.concatenate([y, df_incong.columns.map(lambda x: 1. if '_pa_' in x else 0.).values])\n",
    "\n",
    "    # add omitted trials\n",
    "    df_omis = df_betas.filter(regex='_omis')\n",
    "    X_omis = np.vstack([X, df_omis.values.T])\n",
    "    y_omis = np.concatenate([y, df_omis.columns.map(lambda x: 0. if '_pa_' in x else 1.).values])\n",
    "    \n",
    "    pipeline.set_params(feature_selection__k=max(1,int(X.shape[1]*feature_percentage)))\n",
    "\n",
    "    accs['cong'].append(cross_val_score(pipeline, X, y, cv=LeaveOneOut()))\n",
    "    accs['cong+incong(stim)'].append(cross_val_score(pipeline, X_incong, y_heard, cv=LeaveOneOut()))\n",
    "    accs['cong+incong(pred)'].append(cross_val_score(pipeline, X_incong, y_pred, cv=LeaveOneOut()))\n",
    "    accs['cong+omis'].append(cross_val_score(pipeline, X_omis, y_omis, cv=LeaveOneOut()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade16fce-b719-4005-bd60-19f067cebcbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(16,4))\n",
    "\n",
    "for idx, key in enumerate(accs.keys()):\n",
    "    sns.barplot(accs[key], ax=ax[idx], capsize=.1)\n",
    "    ax[idx].axhline(.5, c='k', linestyle='--')\n",
    "    ax[idx].set_title(key)\n",
    "    ax[idx].set_xticks(range(5), all_betas.keys())\n",
    "    if idx==0: ax[idx].set_ylabel('acc')\n",
    "\n",
    "plt.suptitle('PA vs. GA Classification Results', fontweight='bold', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289b34d-bb34-41bf-a3ac-51e7ce0b42c2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Let's now look at multivariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30a847-fa43-4f73-bf32-2e99027acfe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_percentage = .1\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectFromModel(Lasso(), threshold='mean')),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "accs = {\n",
    "    'cong': [], 'cong+incong(stim)': [], 'cong+incong(pred)': [], 'cong+omis': []\n",
    "}\n",
    "\n",
    "for region, df_betas in all_betas.items():\n",
    "\n",
    "    # prepare congruent trials\n",
    "    df_cong = df_betas.filter(regex='_cong')\n",
    "    X = df_cong.values.T\n",
    "    y = df_cong.columns.map(lambda x: 0. if '_pa_' in x else 1.).values\n",
    "\n",
    "    # add incongruent trials\n",
    "    df_incong = df_betas.filter(regex='_incong')\n",
    "    X_incong = np.vstack([X, df_incong.values.T])\n",
    "    y_heard = np.concatenate([y, df_incong.columns.map(lambda x: 0. if '_pa_' in x else 1.).values])\n",
    "    y_pred = np.concatenate([y, df_incong.columns.map(lambda x: 1. if '_pa_' in x else 0.).values])\n",
    "\n",
    "    # add omitted trials\n",
    "    df_omis = df_betas.filter(regex='_omis')\n",
    "    X_omis = np.vstack([X, df_omis.values.T])\n",
    "    y_omis = np.concatenate([y, df_omis.columns.map(lambda x: 0. if '_pa_' in x else 1.).values])\n",
    "    \n",
    "    accs['cong'].append(cross_val_score(pipeline, X, y, cv=LeaveOneOut()))\n",
    "    accs['cong+incong(stim)'].append(cross_val_score(pipeline, X_incong, y_heard, cv=LeaveOneOut()))\n",
    "    accs['cong+incong(pred)'].append(cross_val_score(pipeline, X_incong, y_pred, cv=LeaveOneOut()))\n",
    "    accs['cong+omis'].append(cross_val_score(pipeline, X_omis, y_omis, cv=LeaveOneOut()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721c83e-4c5c-41da-865e-570e5f381cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(16,4))\n",
    "\n",
    "for idx, key in enumerate(accs.keys()):\n",
    "    sns.barplot(accs[key], ax=ax[idx], capsize=.1)\n",
    "    ax[idx].axhline(.5, c='k', linestyle='--')\n",
    "    ax[idx].set_title(key)\n",
    "    ax[idx].set_xticks(range(5), all_betas.keys())\n",
    "    if idx==0: ax[idx].set_ylabel('acc')\n",
    "\n",
    "plt.suptitle('PA vs. GA Classification Results', fontweight='bold', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c318c09-99b9-4158-849f-a2861432aeea",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbic13",
   "language": "python",
   "name": "mbic13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
